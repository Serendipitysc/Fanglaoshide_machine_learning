{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training_data: (1595, 96) and the shape of training_data_labels: (1595,) the type of the training data is: <class 'numpy.ndarray'>\n",
      "shape of testing_data: (399, 96) and the shape of testing_data_labels: (399,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "'''\n",
    "problem1 function read the data, and format the data to numpy array\n",
    "\n",
    "Return: the numpy array\n",
    "'''\n",
    "def data_reformation(filename):\n",
    "    data = []\n",
    "    ''''load data from .data file to list of list'''\n",
    "    f=open(filename)\n",
    "    sample=f.readlines()\n",
    "    for i in range(len(sample)):\n",
    "        sample[i] = sample[i].strip().split('\\t')\n",
    "\n",
    "    attributes = sample[0]\n",
    "    sample.pop(0)\n",
    "    #print(\"the sample we got right now is:\", len(sample))\n",
    "    for item in sample:\n",
    "        list1=[]\n",
    "        for i in range(len(item)):\n",
    "            list1.append(np.float64(item[i]))\n",
    "        list1.append(np.float64(1))\n",
    "        data.append(list1)\n",
    "    \n",
    "    labels = []\n",
    "    for instance in data:\n",
    "        labels.append(instance[0])\n",
    "        instance.pop(0)\n",
    "    '''convert data to numpy array'''  \n",
    "    prepared_data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return prepared_data, labels\n",
    "\n",
    "training_data, training_data_labels = data_reformation(\"crime-train.txt\")\n",
    "print(\"shape of training_data:\", training_data.shape, \"and the shape of training_data_labels:\", training_data_labels.shape,\"the type of the training data is:\", type(training_data))\n",
    "testing_data, testing_data_labels = data_reformation(\"crime-test.txt\")\n",
    "print(\"shape of testing_data:\", testing_data.shape, \"and the shape of testing_data_labels:\", testing_data_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If lambda equals to: 400 the average RMSE result I got is: 0.14951277619075795\n",
      "If lambda equals to: 200.0 the average RMSE result I got is: 0.14069401845317783\n",
      "If lambda equals to: 100.0 the average RMSE result I got is: 0.13727677223186574\n",
      "If lambda equals to: 50.0 the average RMSE result I got is: 0.13615594392755512\n",
      "If lambda equals to: 25.0 the average RMSE result I got is: 0.13591585919851976\n",
      "If lambda equals to: 12.5 the average RMSE result I got is: 0.13602237446230683\n",
      "If lambda equals to: 6.25 the average RMSE result I got is: 0.13626786494076756\n",
      "If lambda equals to: 3.125 the average RMSE result I got is: 0.136570956936428\n",
      "If lambda equals to: 1.5625 the average RMSE result I got is: 0.13688764073197482\n",
      "If lambda equals to: 0.78125 the average RMSE result I got is: 0.13717626806866834\n",
      "\tthe smallest average RMSE result is 0.13591585919851976 and the lambda value is 25.0\n",
      "the training error of lambda = 25.0 is 0.12879701459879783\n",
      "the testing error of lambda = 25.0 is 0.14574650707057987\n"
     ]
    }
   ],
   "source": [
    "training_data_folders = np.split(training_data, k);\n",
    "training_data_labels_folders = np.split(training_data_labels, k)\n",
    "lambda_values =[]\n",
    "for i in range(10):\n",
    "    if len(lambda_values) == 0:\n",
    "        lambda_values.append(400)\n",
    "    else:\n",
    "        lambda_values.append(lambda_values[i-1]/2)\n",
    "\n",
    "\n",
    "def cross_validation(lambda_value):\n",
    "    ridge_validate_preds=[]\n",
    "    rmses = []\n",
    "    for i in range(len(training_data_folders)):\n",
    "        training = list(training_data_folders)\n",
    "        training.pop(i)\n",
    "        training = np.concatenate(training, axis = 0)\n",
    "        #print(training.shape)\n",
    "        training_labels = list(training_data_labels_folders)\n",
    "        training_labels.pop(i)\n",
    "        #print(training_labels[0].shape)\n",
    "        training_labels = np.concatenate(training_labels)\n",
    "        #print(training_data_labels.shape)\n",
    "        ridge_validate_preds.append(ridge_regression(training, training_labels,training_data_folders[i], lambda_value))\n",
    "        rmses.append(show_rmse(ridge_validate_preds[i],training_data_labels_folders[i] ))\n",
    "    \n",
    "    return sum(rmses)/len(rmses) \n",
    "\n",
    "def ridge_regression(training,training_labels,validation,lambda_value):\n",
    "    i_matrix = np.identity(96, dtype = np.float64())\n",
    "    w =  np.linalg.inv((training).T.dot(training) + lambda_value * i_matrix).dot((training).T).dot(training_labels)\n",
    "    return (validation).dot(w)\n",
    "\n",
    "def show_rmse(pred, ans):\n",
    "    assert len(pred) == len(ans)\n",
    "    sqr_sum = 0\n",
    "    for i, j in zip(pred, ans):\n",
    "        sqr_sum = sqr_sum + (i-j)**2\n",
    "    return (sqr_sum/len(pred))**(1/2)\n",
    "\n",
    "def problem1():\n",
    "    rmse_values = []\n",
    "    for lambda_value in lambda_values:\n",
    "        rmse_values.append(cross_validation(lambda_value))\n",
    "        print(\"If lambda equals to:\", lambda_value,\"the average RMSE result I got is:\",cross_validation(lambda_value))\n",
    "    min_lambda = lambda_values[rmse_values.index(min(rmse_values))]\n",
    "    print(\"\\tthe smallest average RMSE result is\", min(rmse_values),\"and the lambda value is\", min_lambda)\n",
    "    ridge_test_optimal_lambda_pred = ridge_regression(training_data,training_data_labels, testing_data, min_lambda)\n",
    "    ridge_train_optimal_lambda_pred = ridge_regression(training_data,training_data_labels, training_data, min_lambda)\n",
    "    print(\"the training error of lambda =\", min_lambda,\"is\", show_rmse(ridge_train_optimal_lambda_pred,training_data_labels))\n",
    "    print(\"the testing error of lambda =\", min_lambda,\"is\", show_rmse(ridge_test_optimal_lambda_pred,testing_data_labels))\n",
    "problem1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If lambda equals to: 400 the average RMSE result I got is: 0.14951277619075795\n",
    "If lambda equals to: 200.0 the average RMSE result I got is: 0.14069401845317783\n",
    "If lambda equals to: 100.0 the average RMSE result I got is: 0.13727677223186574\n",
    "If lambda equals to: 50.0 the average RMSE result I got is: 0.13615594392755512\n",
    "If lambda equals to: 25.0 the average RMSE result I got is: 0.13591585919851976\n",
    "If lambda equals to: 12.5 the average RMSE result I got is: 0.13602237446230683\n",
    "If lambda equals to: 6.25 the average RMSE result I got is: 0.13626786494076756\n",
    "If lambda equals to: 3.125 the average RMSE result I got is: 0.136570956936428\n",
    "If lambda equals to: 1.5625 the average RMSE result I got is: 0.13688764073197482\n",
    "If lambda equals to: 0.78125 the average RMSE result I got is: 0.13717626806866834\n",
    "\tthe smallest average RMSE result is 0.13591585919851976 and the lambda value is 25.0\n",
    "the training error of lambda = 25.0 is 0.12879701459879783\n",
    "the testing error of lambda = 25.0 is 0.14574650707057987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_t: [0.01051792 0.55135813 0.52269449 0.5661685  0.25271851 0.79230716\n",
      " 0.38895629 0.60838067 0.63140261 0.02892042 0.68455986 0.85470498\n",
      " 0.08975153 0.5868919  0.88927338 0.94680339 0.43563193 0.86242412\n",
      " 0.09258226 0.5931769  0.85601854 0.83310365 0.07571838 0.95690498\n",
      " 0.84478696 0.95936511 0.05882305 0.75092406 0.87466923 0.20121572\n",
      " 0.89509245 0.85738438 0.57261735 0.75825825 0.89668246 0.26093171\n",
      " 0.37629578 0.16761548 0.81550182 0.27243789 0.31501051 0.38238638\n",
      " 0.93965645 0.89854976 0.43339247 0.07027847 0.44061247 0.08993339\n",
      " 0.14014423 0.62500647 0.6609046  0.23664367 0.4522918  0.94631494\n",
      " 0.41319386 0.74297895 0.30129232 0.18549921 0.97460458 0.06305675\n",
      " 0.69342925 0.45586226 0.36306739 0.40786626 0.45763638 0.16604318\n",
      " 0.917921   0.23792413 0.38806221 0.5385568  0.77583291 0.40111849\n",
      " 0.85453367 0.71735098 0.11281745 0.97044276 0.6345596  0.77885326\n",
      " 0.53031864 0.92605493 0.41286201 0.71515847 0.60760953 0.34434347\n",
      " 0.4209883  0.24808751 0.22000989 0.70749169 0.28517014 0.23981848\n",
      " 0.84574919 0.10114325 0.80790597 0.55904231 0.98013556 0.10188391] \n",
      "\n",
      "w_t1 (96,) \n",
      "\n",
      "w_t: [0.73861904 0.86941842 0.95987546 0.85974756 0.49846895 0.68613304\n",
      " 0.33615717 0.77894136 0.43960121 0.36977021 0.50225378 0.62070023\n",
      " 0.00579495 0.24609982 0.91163827 0.35899892 0.62742017 0.96051755\n",
      " 0.13951732 0.49977561 0.8895719  0.57074043 0.96564126 0.53322115\n",
      " 0.72176798 0.3965842  0.56345469 0.93876507 0.93992851 0.71792762\n",
      " 0.54233736 0.83452201 0.62937192 0.70090317 0.3518885  0.05053952\n",
      " 0.49356689 0.45238862 0.05993513 0.74991172 0.95879901 0.71871857\n",
      " 0.38591198 0.82851572 0.27851389 0.75154203 0.26756909 0.0622716\n",
      " 0.22318487 0.54299788 0.23386468 0.26436036 0.63059985 0.28275177\n",
      " 0.59582238 0.35965431 0.85439071 0.45340763 0.30639178 0.94707862\n",
      " 0.74844663 0.88003203 0.73449145 0.14403895 0.08188879 0.49869015\n",
      " 0.19194053 0.16225526 0.27908303 0.17573493 0.33236462 0.11682342\n",
      " 0.10459844 0.5580924  0.24410665 0.85373214 0.80568565 0.51376731\n",
      " 0.7333413  0.73319583 0.06518458 0.27662099 0.45847972 0.98367083\n",
      " 0.56955642 0.14039503 0.1014069  0.79644139 0.03791545 0.75044185\n",
      " 0.49380166 0.24970111 0.43085408 0.01621257 0.19396209 0.53678311] \n",
      "\n",
      "w_t1 (96,) \n",
      "\n",
      "linear test error: 0.14827261229520433 \n",
      "\n",
      "linear train error: 0.13120827601795648 \n",
      "\n",
      "ridge train error: 0.12887205088551643 \n",
      "\n",
      "ridge test error: 0.14579865486890597 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import *\n",
    "epsilon = 10**-5\n",
    "#linear test error: 0.14550044963059267 \n",
    "#linear train error: 0.12928590193840733 \n",
    "#alpha = 0.00000845\n",
    "def problem2(samples):\n",
    "    alpha = 0.00000845\n",
    "    w_initial = []\n",
    "    for i in range(96):\n",
    "        w_initial.append(np.float64(random()))\n",
    "    w_t = np.array(w_initial)\n",
    "    print(\"w_t:\",w_t,\"\\n\")\n",
    "    w_t1 = w_t + alpha*((training_data).T.dot(training_data_labels-((training_data).dot(w_t))))\n",
    "    print(\"w_t1\",w_t1.shape,\"\\n\")\n",
    "    while weight_compare(w_t, w_t1) == False:\n",
    "        w_t = w_t1\n",
    "        #print(\"w_t:\",w_t,\"\\n\")\n",
    "        w_t1 = w_t + alpha*((training_data).T.dot(training_data_labels-((training_data).dot(w_t))))\n",
    "        #print(\"w_t1:\",w_t1,\"\\n\")\n",
    "    return (samples).dot(w_t1)\n",
    "\n",
    "def weight_compare(w1, w2):\n",
    "    assert len(w1) == len(w2)\n",
    "    for i in range(len(w1)):\n",
    "        if abs(w1[i]-w2[i])>=(epsilon):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def problem3(samples):\n",
    "    alpha = 0.0000085\n",
    "    w_initial = []\n",
    "    for i in range(96):\n",
    "        w_initial.append(np.float64(random()))\n",
    "    w_t = np.array(w_initial)\n",
    "    rmse_values = []\n",
    "    for lambda_value in lambda_values:\n",
    "        rmse_values.append(cross_validation(lambda_value))\n",
    "        #print(\"If lambda equals to:\", lambda_value,\"the average RMSE result I got is:\",cross_validation(lambda_value))\n",
    "    min_lambda = lambda_values[rmse_values.index(min(rmse_values))]\n",
    "    i_matrix = np.identity(96, dtype = np.float64())\n",
    "    w_t1 = w_t + alpha*((training_data).T.dot(training_data_labels-((training_data).dot(w_t))) - min_lambda*w_t)\n",
    "    while weight_compare(w_t, w_t1) == False:\n",
    "        w_t = w_t1\n",
    "        #print(\"w_t:\",w_t,\"\\n\")\n",
    "        w_t1 = w_t + alpha*((training_data).T.dot(training_data_labels-((training_data).dot(w_t))) - min_lambda*w_t)\n",
    "        #print(\"w_t1:\",w_t1,\"\\n\")\n",
    "    return (samples).dot(w_t1)\n",
    "linear_train_pred = problem2(training_data)\n",
    "linear_test_pred = problem2(testing_data)\n",
    "ridge_test_pred = problem3(testing_data)\n",
    "ridge_train_pred = problem3(training_data)\n",
    "print(\"linear test error:\",show_rmse(linear_test_pred, testing_data_labels),\"\\n\")\n",
    "print(\"linear train error:\",show_rmse(linear_train_pred, training_data_labels),\"\\n\")\n",
    "print(\"ridge train error:\",show_rmse(ridge_train_pred, training_data_labels),\"\\n\")\n",
    "print(\"ridge test error:\",show_rmse(ridge_test_pred, testing_data_labels),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem 2: \n",
    "alpha = 0.00000845\n",
    "linear test error: 0.14550044963059267 \n",
    "linear train error: 0.12928590193840733 \n",
    "In the lab4 I get linear test error: 0.1458346449094907 and linear train error: 0.12768967421762192. It is really close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem3:\n",
    "alpha = 0.0000085\n",
    "The closes result I get is:\n",
    "ridge train error: 0.12887069926895178 \n",
    "ridge test error: 0.14570432563991323 \n",
    "It is very close to the result in Exercise 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
