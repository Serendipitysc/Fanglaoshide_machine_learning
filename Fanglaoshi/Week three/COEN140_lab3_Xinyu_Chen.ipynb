{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import perf_counter\n",
    "data = []\n",
    "labels = ['Iris-setosa', 'Iris-versicolor','Iris-virginica']\n",
    "'''\n",
    "Function to test the correct format of list of list\n",
    "\n",
    "Return: Boolen\n",
    "'''\n",
    "def multivariate_guassian(x, mu, cov):\n",
    "    #print(mu)\n",
    "    #print(\"x:\", x)\n",
    "    #print(\"shape cov:\", cov.shape)\n",
    "    #assert(mu.shape[0] > mu.shape[1])\n",
    "    #assert(x.shape[0] > x.shape[1])\n",
    "    #assert(cov.shape[0] == cov.shape[1])\n",
    "    #assert(mu.shape[0] == cov.shape[0])\n",
    "    #assert(mu.shape[0] == x.shape[0])\n",
    "    part1 = 1 / ( ((2* np.pi)**(len(mu)/2)) * (np.linalg.det(cov)**(1/2)) )\n",
    "    part2 = (-1/2) * ((x-mu).T.dot(np.linalg.inv(cov))).dot((x-mu))\n",
    "    return float(part1 * np.exp(part2))\n",
    "\n",
    "def test_dataset(data):\n",
    "    if len(data) != 150:\n",
    "        return False\n",
    "   \n",
    "    for row in data:\n",
    "        if len(row) != 5:\n",
    "            return False\n",
    "       \n",
    "        for column in row[:-1]:\n",
    "            if type(column) != np.float64:\n",
    "                print(\"not float is a \", type(column), column)\n",
    "                return False\n",
    "           \n",
    "        if type(row[-1]) != str:\n",
    "            print(\"not a string\")\n",
    "            return False\n",
    "   \n",
    "    return True\n",
    "\n",
    "\n",
    "'''\n",
    "problem1 function read the data, and format the data to numpy array\n",
    "\n",
    "Return: the numpy array\n",
    "'''\n",
    "def problem1():\n",
    "\n",
    "    ''''load data from .data file to list of list'''\n",
    "    f=open(\"iris.data\")\n",
    "    sample=f.readlines()\n",
    "    for i in range(len(sample)):\n",
    "        sample[i] = sample[i].strip().split(',')\n",
    "\n",
    "    for item in sample:\n",
    "        list=[]\n",
    "        for i in range(len(item)):\n",
    "            if i!=(len(item)-1):\n",
    "                list.append(np.float64(item[i]))\n",
    "            else:\n",
    "                list.append(item[i])\n",
    "        data.append(list)\n",
    "\n",
    "    print(\"the test_dataset function returns:\",test_dataset(data))\n",
    "    '''convert data to numpy array'''  \n",
    "    prepared_data = np.array(data)\n",
    "    return prepared_data\n",
    "\n",
    "'''\n",
    "Function parse the data into numpy arrays of data and labels:\n",
    "\n",
    "Return the numpy data and labels\n",
    "'''   \n",
    "\n",
    "def parse_data(data):\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "    training_data_labels = []\n",
    "    testing_data_labels = []\n",
    "    '''separate training data and testing data into list of list forms'''\n",
    "    for i in range(len(data)):\n",
    "        if i in range(0,40) or i in range(50,90) or i in range(100, 140):\n",
    "            training_data.append(data[i])\n",
    "        else:\n",
    "            testing_data.append(data[i])\n",
    "\n",
    "    '''separate the labels and data in list of list forms'''\n",
    "    for ii in range(len(training_data)):\n",
    "        training_data_labels.append(training_data[ii][-1])\n",
    "        training_data[ii]=training_data[ii][:len(training_data[ii])-1]\n",
    "\n",
    "\n",
    "    for jj in range(len(testing_data)):\n",
    "        testing_data_labels.append(testing_data[jj][-1])\n",
    "        testing_data[jj]=testing_data[jj][:len(testing_data[jj])-1]\n",
    "\n",
    "\n",
    "    '''convert everything into numpy array'''\n",
    "    training_data = np.array(training_data)\n",
    "    training_data_labels = np.array(training_data_labels)\n",
    "    testing_data = np.array(testing_data)\n",
    "    testing_data_labels = np.array(testing_data_labels)\n",
    "    print(\"No column has been removed:\")\n",
    "    return training_data,training_data_labels,testing_data,testing_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test_dataset function returns: True\n",
      "No column has been removed:\n",
      "class Iris-setosa  is linearly separable from other classes\n",
      "\n",
      "class Iris-versicolor  is not linearly separable from other classes\n",
      "\n",
      "class Iris-virginica  is not linearly separable from other classes\n",
      "\n",
      "prob: 2.6334487281988994\n",
      "prob: 0.000704224497621299\n",
      "prob: 1.2797129825751623\n",
      "prob: 0.44560417948035014\n",
      "prob: 0.5592821374039403\n",
      "prob: 0.8078768385641917\n",
      "prob: 0.9574939878116792\n",
      "prob: 1.9176901807137046\n",
      "prob: 2.207605763721707\n",
      "prob: 3.2140196361965585\n",
      "prob: 2.3308322759873276e-22\n",
      "prob: 5.963135014422311e-21\n",
      "prob: 3.3896825296740197e-17\n",
      "prob: 1.3816009527360964e-14\n",
      "prob: 6.312063883598827e-20\n",
      "prob: 5.241170722173605e-17\n",
      "prob: 2.722830509442705e-18\n",
      "prob: 1.788346676528355e-17\n",
      "prob: 2.938473496219504e-12\n",
      "prob: 5.8871082682836914e-18\n",
      "prob: 4.528644934866535e-44\n",
      "prob: 2.3654214079377137e-37\n",
      "prob: 1.5016281764966944e-36\n",
      "prob: 5.667953269676251e-44\n",
      "prob: 1.573197375949117e-45\n",
      "prob: 2.5601260682465463e-39\n",
      "prob: 1.9449187174443125e-35\n",
      "prob: 1.2780988495067343e-33\n",
      "prob: 9.266323761091855e-40\n",
      "prob: 2.6854940299191937e-32\n",
      "prob: 3.325871774581662\n",
      "prob: 1.2028206670632997\n",
      "prob: 2.6303340241246578\n",
      "prob: 1.218692420107859\n",
      "prob: 2.7780940135641874\n",
      "prob: 1.4621666427348952\n",
      "prob: 1.7645257638445593\n",
      "prob: 3.4242893328885597\n",
      "prob: 0.5139543443227079\n",
      "prob: 1.81742305425046\n",
      "prob: 1.9537117508494566\n",
      "prob: 1.6076312157445374\n",
      "prob: 1.496232683288672\n",
      "prob: 1.1045451121525625\n",
      "prob: 0.03231040224816828\n",
      "prob: 0.03813590879626394\n",
      "prob: 0.4474094244535257\n",
      "prob: 2.970794725454166\n",
      "prob: 1.2922641486662614\n",
      "prob: 1.7848626101754503\n",
      "prob: 2.4020512620567116\n",
      "prob: 2.1669472842785638\n",
      "prob: 1.2573123113790934\n",
      "prob: 0.7249319623197658\n",
      "prob: 0.1880601826899353\n",
      "prob: 1.0755509296371033\n",
      "prob: 2.1444388773421763\n",
      "prob: 3.285006846958813\n",
      "prob: 2.7121916230482355\n",
      "prob: 1.2554700952917048\n",
      "prob: 1.4259552134258808\n",
      "prob: 0.7213942217864244\n",
      "prob: 0.06048185693328508\n",
      "prob: 0.09844233299110099\n",
      "prob: 1.81742305425046\n",
      "prob: 1.402772462033034\n",
      "prob: 0.5869682279471489\n",
      "prob: 1.81742305425046\n",
      "prob: 0.9571402805704189\n",
      "prob: 3.4836641582082395\n",
      "prob: 2.669928357545045e-18\n",
      "prob: 7.396962336687619e-19\n",
      "prob: 8.107260393055659e-22\n",
      "prob: 1.1765584478712396e-21\n",
      "prob: 2.478296279707248e-22\n",
      "prob: 4.920576347763669e-22\n",
      "prob: 1.3636078562156604e-21\n",
      "prob: 3.361343632328197e-14\n",
      "prob: 3.830311490363587e-19\n",
      "prob: 4.8796126089638184e-20\n",
      "prob: 1.4021516292406014e-18\n",
      "prob: 4.1725561093798394e-19\n",
      "prob: 2.13505214368409e-18\n",
      "prob: 1.3125458593751885e-22\n",
      "prob: 6.145518111030993e-14\n",
      "prob: 4.282610224481647e-17\n",
      "prob: 2.2282753969848437e-23\n",
      "prob: 7.618734532816077e-16\n",
      "prob: 4.696814760160484e-28\n",
      "prob: 9.600137346234438e-17\n",
      "prob: 1.3855387565706783e-27\n",
      "prob: 3.513647177029438e-16\n",
      "prob: 3.5318325043943883e-28\n",
      "prob: 1.1862639080874343e-21\n",
      "prob: 4.4636955556305274e-17\n",
      "prob: 6.618365989925561e-18\n",
      "prob: 2.430033204121938e-22\n",
      "prob: 2.2041019021221156e-26\n",
      "prob: 4.978874333870081e-22\n",
      "prob: 4.361042984914292e-12\n",
      "prob: 5.4180771648615886e-17\n",
      "prob: 2.5497928544643164e-15\n",
      "prob: 1.0516900867835539e-15\n",
      "prob: 2.8872734041279305e-31\n",
      "prob: 1.1743249653379178e-24\n",
      "prob: 1.669172194246616e-20\n",
      "prob: 1.7838686613788124e-20\n",
      "prob: 2.804252223807437e-23\n",
      "prob: 2.851675323092395e-17\n",
      "prob: 6.088718894894807e-20\n",
      "prob: 1.6522089390825016e-51\n",
      "prob: 1.5016281764966944e-36\n",
      "prob: 7.207930072188911e-41\n",
      "prob: 3.4895890497961242e-37\n",
      "prob: 4.80361212531342e-44\n",
      "prob: 3.8531076621427294e-48\n",
      "prob: 1.3552091603945941e-33\n",
      "prob: 5.519744300396696e-42\n",
      "prob: 2.708872294012407e-41\n",
      "prob: 2.037318697003046e-45\n",
      "prob: 4.771911307631524e-31\n",
      "prob: 5.186080991163264e-36\n",
      "prob: 1.7882627708333956e-37\n",
      "prob: 1.4864125625647824e-39\n",
      "prob: 7.788020472805104e-46\n",
      "prob: 3.827721626633028e-39\n",
      "prob: 5.593461201468035e-34\n",
      "prob: 7.75292372009478e-45\n",
      "prob: 5.961715239452029e-60\n",
      "prob: 2.845746812597962e-33\n",
      "prob: 2.651011198228352e-41\n",
      "prob: 2.8146266378019576e-36\n",
      "prob: 9.75047262276964e-50\n",
      "prob: 1.1255314145101928e-30\n",
      "prob: 1.003344091739837e-37\n",
      "prob: 6.98792707731569e-36\n",
      "prob: 3.8202595340654715e-29\n",
      "prob: 6.692981148002546e-29\n",
      "prob: 5.200210861570209e-42\n",
      "prob: 1.4197373010776124e-32\n",
      "prob: 4.1075568043788365e-41\n",
      "prob: 4.3754094791480945e-37\n",
      "prob: 6.380706918114453e-44\n",
      "prob: 5.995522434305488e-28\n",
      "prob: 6.828351676798049e-37\n",
      "prob: 1.2361787237296208e-45\n",
      "prob: 1.6292112178108422e-43\n",
      "prob: 7.08893488577385e-34\n",
      "prob: 2.542608433240322e-28\n",
      "prob: 2.5580961611919167e-35\n",
      "LDA test error: 0.0 % \n",
      "\n",
      "LDA train error: 2.5 %\n",
      "QDA test error: 0.0 %\n",
      " \ttime cost is: 0.002865399999791407 \n",
      "\n",
      "QDA train error: 1.6666666666666667 %\n",
      " \ttime cost is: 0.010508900000331778 \n",
      "\n",
      "QDA diagnoal matrix test error: 0.0 %\n",
      " \ttime cost is: 0.0027976999999737018 \n",
      "\n",
      "QDA diagnoal matrix train error: 4.166666666666666 %\n",
      " \ttime cost is: 0.009976100000130828 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def diag(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[i])):\n",
    "            if (i!=0 or j!=0) and (i!=1 or j!=1) and (i!=2 or j!=2) and (i!=3 or j!=3):\n",
    "                matrix[i][j]=0\n",
    "    return matrix\n",
    "'''\n",
    "My LDA Implementation\n",
    "'''\n",
    "def problem2(sample):\n",
    "    sample_data = [training_data[0:40],training_data[40:80],training_data[80:120]]\n",
    "    mean = []\n",
    "    covars = []\n",
    "    probs = []\n",
    "    result = []\n",
    "    predictions = []\n",
    "    covar = 0\n",
    "    for item in sample_data:\n",
    "        #print(\"shape item:\", item.shape)\n",
    "        #mean.append(np.mean(item, axis=0).reshape(4,1))\n",
    "        mean.append(np.mean(item, axis=0))\n",
    "        covars.append(np.cov(item, rowvar = False))\n",
    "    for ii in range(len(covars)):\n",
    "        covar = covar + covars[ii]\n",
    "    covar = covar / len(covars)\n",
    "    #print(\"testing\", testing_data)\n",
    "    for instance in sample:\n",
    "        prob=[]\n",
    "        for i in range(len(mean)):\n",
    "            #reshape_instance = instance.reshape(4,1)\n",
    "            #print(\"calculating the prob for\", labels[i])\n",
    "            #prob.append(multivariate_guassian(reshape_instance, mean[i], covar[i]))\n",
    "            prob.append(multivariate_guassian(instance, mean[i], covar))\n",
    "        probs.append(prob)\n",
    "        #print(prob)\n",
    "    \n",
    "    for prob in probs:\n",
    "        print(\"prob:\",prob[0])\n",
    "        result.append(prob.index(max(prob)))\n",
    "    \n",
    "    for j in result:\n",
    "        predictions.append(labels[j])\n",
    "    return np.array(predictions)\n",
    "\n",
    "'''\n",
    "My own QDA Implementation\n",
    "'''\n",
    "def problem3(sample):\n",
    "    sample_data = [training_data[0:40],training_data[40:80],training_data[80:120]]\n",
    "    mean = []\n",
    "    covar = []\n",
    "    probs = []\n",
    "    result = []\n",
    "    predictions = []\n",
    "    for item in sample_data:\n",
    "        #print(\"shape item:\", item.shape)\n",
    "        #mean.append(np.mean(item, axis=0).reshape(4,1))\n",
    "        mean.append(np.mean(item, axis=0))\n",
    "        covar.append(np.cov(item, rowvar = False))\n",
    "    assert (len(mean) == len(covar))\n",
    "    \n",
    "    #print(\"testing\", testing_data)\n",
    "    for instance in sample:\n",
    "        prob=[]\n",
    "        for i in range(len(mean)):\n",
    "            #reshape_instance = instance.reshape(4,1)\n",
    "            #print(\"calculating the prob for\", labels[i])\n",
    "            #prob.append(multivariate_guassian(reshape_instance, mean[i], covar[i]))\n",
    "            prob.append(multivariate_guassian(instance, mean[i], covar[i]))\n",
    "        probs.append(prob)\n",
    "        #print(prob)\n",
    "    \n",
    "    for prob in probs:\n",
    "        #print(\"prob:\",prob)\n",
    "        result.append(prob.index(max(prob)))\n",
    "    \n",
    "    for j in result:\n",
    "        predictions.append(labels[j])\n",
    "    return np.array(predictions)\n",
    "        \n",
    "\n",
    "\n",
    "def problem4(sample):\n",
    "    assert(attribute<3)\n",
    "    if attribute == 0:\n",
    "        sample_data = [training_data[0:40],training_data[40:120]]\n",
    "    elif attribute == 1:\n",
    "        #print (type(sample[40:80]))\n",
    "        sample_data = [training_data[40:80],np.concatenate((training_data[0:40],training_data[80:120]), axis=0)]\n",
    "    else:\n",
    "        sample_data = [training_data[80:120],training_data[0:80]]\n",
    "    mean = []\n",
    "    covar = []\n",
    "    probs = []\n",
    "    result = []\n",
    "    predictions = []\n",
    "    for item in sample_data:\n",
    "        #print(\"shape item:\", item.shape)\n",
    "        #mean.append(np.mean(item, axis=0).reshape(4,1))\n",
    "        mean.append(np.mean(item, axis=0))\n",
    "        covar.append(np.cov(item, rowvar = False))\n",
    "    assert (len(mean) == len(covar))\n",
    "    \n",
    "    #print(\"testing\", testing_data)\n",
    "    for instance in sample:\n",
    "        prob=[]\n",
    "        for i in range(len(mean)):\n",
    "            #reshape_instance = instance.reshape(4,1)\n",
    "            #print(\"calculating the prob for\", labels[i])\n",
    "            #prob.append(multivariate_guassian(reshape_instance, mean[i], covar[i]))\n",
    "            prob.append(multivariate_guassian(instance, mean[i], covar[i]))\n",
    "        probs.append(prob)\n",
    "        #print(prob)\n",
    "    \n",
    "    for prob in probs:\n",
    "        #print(\"prob:\",prob)\n",
    "        if attribute == 0:\n",
    "            if prob[0]>prob[1]:\n",
    "                predictions.append('Iris-setosa')\n",
    "            else:\n",
    "                predictions.append('other than Iris-setosa')\n",
    "        elif attribute == 1:\n",
    "            if prob[0]>prob[1]:\n",
    "                predictions.append('Iris-versicolor')\n",
    "            else:\n",
    "                predictions.append('other than Iris-versicolor')\n",
    "        else:\n",
    "            if prob[0]>prob[1]:\n",
    "                predictions.append('Iris-virginica')\n",
    "            else:\n",
    "                predictions.append('other than Iris-virginica')\n",
    "            \n",
    "    return np.array(predictions)\n",
    "\n",
    "    \n",
    "def problem5(sample):\n",
    "    sample_data = [training_data[0:40],training_data[40:80],training_data[80:120]]\n",
    "    mean = []\n",
    "    covar = []\n",
    "    probs = []\n",
    "    result = []\n",
    "    predictions = []\n",
    "    for item in sample_data:\n",
    "        #print(\"shape item:\", item.shape)\n",
    "        #mean.append(np.mean(item, axis=0).reshape(4,1))\n",
    "        mean.append(np.mean(item, axis=0))\n",
    "        matrix = diag(np.cov(item, rowvar = False))\n",
    "        covar.append(matrix)\n",
    "    assert (len(mean) == len(covar))\n",
    "    \n",
    "    #print(\"testing\", testing_data)\n",
    "    for instance in sample:\n",
    "        prob=[]\n",
    "        for i in range(len(mean)):\n",
    "            #reshape_instance = instance.reshape(4,1)\n",
    "            #print(\"calculating the prob for\", labels[i])\n",
    "            #prob.append(multivariate_guassian(reshape_instance, mean[i], covar[i]))\n",
    "            prob.append(multivariate_guassian(instance, mean[i], covar[i]))\n",
    "        probs.append(prob)\n",
    "        #print(prob)\n",
    "    \n",
    "    for prob in probs:\n",
    "        #print(\"prob:\",prob)\n",
    "        result.append(prob.index(max(prob)))\n",
    "    \n",
    "    for j in result:\n",
    "        predictions.append(labels[j])\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "def show_linear_separable(pred, ans):\n",
    "    if attribute == 0:\n",
    "        for i in range(0,10):\n",
    "            #print(pred[i], ans[i])\n",
    "            if pred[i] != ans[i]:\n",
    "                return False\n",
    "    elif attribute == 1:\n",
    "        for i, j in zip(range(10,20),range(10,20)):\n",
    "            if pred[i] != ans[j]:\n",
    "                return False\n",
    "    elif attribute  == 2:\n",
    "        for i, j in zip(range(20,30), range(20,30)):\n",
    "            #print(pred[i], ans[i])\n",
    "            if pred[i]!=ans[j]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def show_score(ans1, ans2):\n",
    "    counter = 0\n",
    "    #print(len(ans1), len(ans2))\n",
    "    assert(len(ans1)==len(ans2))\n",
    "    for i in range(len(ans1)):\n",
    "        if ans1[i]!=ans2[i]:\n",
    "            counter = counter + 1\n",
    "    return counter/len(ans1)\n",
    "problem1()\n",
    "training_data,training_data_labels,testing_data,testing_data_labels = parse_data(data)\n",
    "#print(\"length of testing_data:\", len(testing_data))\n",
    "#print(\"length of training_data\",len(training_data))\n",
    "for attribute in range(0,3):\n",
    "    pred = problem4(training_data)\n",
    "    #print(labels[attribute],\"result is\", pred)\n",
    "    if show_linear_separable(pred, testing_data_labels) == True:\n",
    "        print(\"class\", labels[attribute],\" is linearly separable from other classes\\n\")\n",
    "    else:\n",
    "        print(\"class\", labels[attribute],\" is not linearly separable from other classes\\n\")\n",
    "LDA_test_pred = problem2(testing_data)\n",
    "\n",
    "regular_test_qda = perf_counter()\n",
    "QDA_test_pred = problem3(testing_data)\n",
    "regular_test_qda_time = perf_counter() - regular_test_qda\n",
    "\n",
    "diagonal_test_qda = perf_counter()\n",
    "QDA_d_test_pred = problem5(testing_data)\n",
    "diagonal_test_qda_time = perf_counter() - diagonal_test_qda\n",
    "\n",
    "\n",
    "LDA_train_pred = problem2(training_data)\n",
    "\n",
    "regular_train_qda = perf_counter()\n",
    "QDA_train_pred = problem3(training_data)\n",
    "regular_train_qda_time = perf_counter() - regular_train_qda\n",
    "\n",
    "diagonal_train_qda = perf_counter()\n",
    "QDA_d_train_pred = problem5(training_data)\n",
    "diagonal_train_qda_time = perf_counter() - diagonal_train_qda\n",
    "\n",
    "\n",
    "\n",
    "print(\"LDA test error:\",show_score(LDA_test_pred, testing_data_labels)*100,\"%\",\"\\n\")\n",
    "print(\"LDA train error:\",show_score(LDA_train_pred, training_data_labels)*100,\"%\")\n",
    "print(\"QDA test error:\",show_score(QDA_test_pred, testing_data_labels)*100,\"%\\n\", \"\\ttime cost is:\", regular_test_qda_time,\"\\n\")\n",
    "print(\"QDA train error:\",show_score(QDA_train_pred, training_data_labels)*100,\"%\\n\", \"\\ttime cost is:\", regular_train_qda_time,\"\\n\")\n",
    "print(\"QDA diagnoal matrix test error:\",show_score(QDA_d_test_pred, testing_data_labels)*100,\"%\\n\", \"\\ttime cost is:\", diagonal_test_qda_time,\"\\n\")\n",
    "print(\"QDA diagnoal matrix train error:\",show_score(QDA_d_train_pred, training_data_labels)*100,\"%\\n\", \"\\ttime cost is:\", diagonal_train_qda_time,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on the experiment, we can conclude that both Iris-setosa is linearly separable from other classes. I just group one class by itself and group other classes to another group. If I can still get perfect LDA result, then the class is linearly separable from other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
